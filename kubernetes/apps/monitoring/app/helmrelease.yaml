apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: monitoring
  namespace: monitoring
spec:
  interval: 10m
  chart:
    spec:
      chart: kube-prometheus-stack
      version: "73.2.3"
      sourceRef:
        kind: HelmRepository
        name: prometheus-community
        namespace: flux-system
  values:
    grafana:
      admin:
        existingSecret: "grafana-admin-credentials"
      persistence:
        enabled: true
        type: sts
        storageClassName: "truenas-iscsi"
        accessModes:
          - ReadWriteOnce
        size: 8Gi
    prometheus:
      prometheusSpec:
        additionalScrapeConfigs:
          - job_name: "tibber"
            static_configs:
              - targets: ["tibber-exporter-scraper.monitoring.svc.cluster.local:8080"]
        scrapeInterval: "15s"
        storageSpec:
          volumeClaimTemplate:
            spec:
              storageClassName: truenas-iscsi
              accessModes: ["ReadWriteOnce"]
              resources:
                requests:
                  storage: 35Gi
---
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: tibber-exporter
  namespace: monitoring
spec:
  interval: 10m
  chart:
    spec:
      chart: tibber-exporter
      version: "3.10.0"
      sourceRef:
        kind: HelmRepository
        name: tibber-exporter
        namespace: flux-system
  valuesFrom:
    - kind: Secret
      name: tibber-api-secret
      valuesKey: TIBBER_API_TOKEN  # Key inside the Secret
      targetPath: tibberToken      # Where it should go in Helm values
  values:
    serviceMonitor:
      enabled: true
---
apiVersion: v1
kind: Service
metadata:
  name: tibber-exporter-scraper
  namespace: monitoring
spec:
  selector:
    app.kubernetes.io/name: tibber-exporter
  ports:
    - protocol: TCP
      port: 8080
      targetPort: 8080
  type: ClusterIP
---
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: loki
  namespace: monitoring
spec:
  interval: 10m
  chart:
    spec:
      chart: loki
      version: "6.29.0"
      sourceRef:
        kind: HelmRepository
        name: grafana
        namespace: flux-system
  values:
    loki:
      auth_enabled: false
      commonConfig:
        replication_factor: 3
      schemaConfig:
        configs:
          - from: "2024-04-01"
            store: tsdb
            object_store: s3
            schema: v13
            index:
              prefix: loki_index_
              period: 24h
      ingester:
        chunk_encoding: snappy
      querier:
        max_concurrent: 4
      pattern_ingester:
        enabled: true
      limits_config:
        volume_enabled: true
        allow_structured_metadata: true
        retention_period: 744h  # 31 days retention
    deploymentMode: SimpleScalable
    backend:
      replicas: 2
    read:
      replicas: 2
    write:
      replicas: 3
    minio:
      enabled: true
      persistence:
        enabled: true
        storageClass: "truenas-iscsi"
        size: 125Gi
    gateway:
      auth:
        enabled: false
      service:
        type: LoadBalancer
    test:
      enabled: false
    lokiCanary:
      enabled: false
---
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: promtail
  namespace: monitoring
spec:
  interval: 10m
  chart:
    spec:
      chart: promtail
      version: "6.16.6"
      sourceRef:
        kind: HelmRepository
        name: grafana
        namespace: flux-system
  values:
    auth_enabled: false
    config:
      clients:
        - url: "http://loki-gateway.monitoring.svc.cluster.local/loki/api/v1/push"
      snippets:
        pipelineStages:
          - cri: {}
  
          - drop:
              expression: '.*(HEAD|GET) / HTTP/1.1'
          - drop:
              expression: '.*(healthz|favicon.ico).*'
  
          - drop:
              expression: '.*  204 .*'
  
          - drop:
              expression: '".*"\s+"-"\s+"-".*'

    extraArgs:
      - -config.expand-env=true
    tolerations:
      - effect: NoSchedule
        key: node-role.kubernetes.io/control-plane
        operator: Exists
    serviceMonitor:
      enabled: true


